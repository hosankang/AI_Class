{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D, MaxPooling2D,LeakyReLU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n",
      "(48000,)\n",
      "[7 8 9 ... 6 4 2]\n",
      "(12000,)\n",
      "[0 2 6 ... 2 8 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# 레이블 정의\n",
    "fashion_mnist_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "                        \"Sandal\",     \"Shirt\",  \"Sneaker\", \"Bag\",  \"Ankle boot\"]\n",
    "\n",
    "#데이터 전처리\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "#학습용과 검증용으로 분리\n",
    "x_train, y_train, x_validate, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 28,28,1)\n",
    "#x_validate = x_validate.reshape(x_validate.shape[0], 28,28,1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_validate)\n",
    "print(y_validate.shape)\n",
    "print(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 21:07:31.794304 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 21:07:31.823844 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 21:07:31.829838 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0819 21:07:31.842849 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0819 21:07:31.844841 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0819 21:07:31.851841 10364 deprecation.py:506] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0819 21:07:31.862847 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model_1\n",
    "cnn_model_1 = Sequential([\n",
    "    Conv2D(32, kernel_size=3,input_shape=[28,28,1],activation='relu', kernel_initializer='he_normal'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64, kernel_size=3,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, kernel_size=3,activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    #fully connected\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "    ], name='Model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 21:07:34.898523 10364 deprecation_wrapper.py:119] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 21:07:34.967530 10364 deprecation.py:323] From C:\\Users\\hosan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.8346 - acc: 0.7014 - val_loss: 0.4824 - val_acc: 0.8212\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.4587 - acc: 0.8312 - val_loss: 0.3900 - val_acc: 0.8626\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3897 - acc: 0.8577 - val_loss: 0.3418 - val_acc: 0.8748\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3522 - acc: 0.8695 - val_loss: 0.3378 - val_acc: 0.8758\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.3191 - acc: 0.8825 - val_loss: 0.3046 - val_acc: 0.8892\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2956 - acc: 0.8904 - val_loss: 0.2787 - val_acc: 0.9012\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2776 - acc: 0.8966 - val_loss: 0.2585 - val_acc: 0.9081\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2659 - acc: 0.9010 - val_loss: 0.2596 - val_acc: 0.9047\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2508 - acc: 0.9063 - val_loss: 0.2499 - val_acc: 0.9096\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2382 - acc: 0.9103 - val_loss: 0.2395 - val_acc: 0.9156\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2275 - acc: 0.9156 - val_loss: 0.2377 - val_acc: 0.9156\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.2184 - acc: 0.9186 - val_loss: 0.2283 - val_acc: 0.9167\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.2130 - acc: 0.9204 - val_loss: 0.2527 - val_acc: 0.9099\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.2026 - acc: 0.9245 - val_loss: 0.2270 - val_acc: 0.9179\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1938 - acc: 0.9271 - val_loss: 0.2289 - val_acc: 0.9193\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1884 - acc: 0.9279 - val_loss: 0.2202 - val_acc: 0.9217\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1831 - acc: 0.9309 - val_loss: 0.2219 - val_acc: 0.9222\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1749 - acc: 0.9350 - val_loss: 0.2204 - val_acc: 0.9203\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1694 - acc: 0.9355 - val_loss: 0.2158 - val_acc: 0.9217\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1667 - acc: 0.9368 - val_loss: 0.2192 - val_acc: 0.9204\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.1620 - acc: 0.9372 - val_loss: 0.2171 - val_acc: 0.9223\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1524 - acc: 0.9418 - val_loss: 0.2120 - val_acc: 0.9262\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.1501 - acc: 0.9426 - val_loss: 0.2122 - val_acc: 0.9265\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.1435 - acc: 0.9441 - val_loss: 0.2226 - val_acc: 0.9228\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.1373 - acc: 0.9483 - val_loss: 0.2149 - val_acc: 0.9287\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1334 - acc: 0.9496 - val_loss: 0.2224 - val_acc: 0.9242\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1293 - acc: 0.9496 - val_loss: 0.2176 - val_acc: 0.9275\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1255 - acc: 0.9523 - val_loss: 0.2187 - val_acc: 0.9289\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1217 - acc: 0.9532 - val_loss: 0.2257 - val_acc: 0.9261\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1195 - acc: 0.9553 - val_loss: 0.2290 - val_acc: 0.9242\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1177 - acc: 0.9554 - val_loss: 0.2207 - val_acc: 0.9274\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1179 - acc: 0.9554 - val_loss: 0.2215 - val_acc: 0.9282\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_dict = {}\n",
    "\n",
    "#Early_stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience = 10, verbose=1, mode='auto')\n",
    "\n",
    "cnn_model_1.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "#훈련\n",
    "history = cnn_model_1.fit(\n",
    "        x_train, x_validate,\n",
    "        batch_size=512,\n",
    "        epochs=100, verbose=2,\n",
    "        validation_data=(y_train, y_validate),\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
